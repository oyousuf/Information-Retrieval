{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "announced-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "The words_before/after list would look like \n",
    "\n",
    "[['~'], '598'],\n",
    " ['-'], '143'],\n",
    " ... \n",
    " \n",
    "\n",
    "'''\n",
    "\n",
    "with open('index_before.txt') as f:\n",
    "    # before lower casing\n",
    "    words_before = [line.split() for line in f.read().split('\\n') if line]\n",
    "    \n",
    "\n",
    "with open('index_after.txt') as f:\n",
    "    # after lower casing \n",
    "    words_after = [line.split() for line in f.read().split('\\n') if line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "expanded-collar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52788\n",
      "50966\n"
     ]
    }
   ],
   "source": [
    "print(len(words_before)) # the length of words before lower casing - 52788\n",
    "print(len(words_after)) # the length of words after lower casing  - 50966"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "rolled-jordan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  to get the 10 most frequent words from the lowercased test collections\n",
    "def stop_words(dictionary, top_n_words): \n",
    "    stop_words = []\n",
    "    i = 0\n",
    "    for k in sorted(vocab, key=lambda k: len(vocab[k]), reverse=True):\n",
    "        if i < top_n_words:\n",
    "            stop_words.append(k)\n",
    "        i += 1\n",
    "        \n",
    "    return stop_words\n",
    "\n",
    "def inverted_index(indexlist, stop_words_processing = False, query=None):\n",
    "    vocab = {}\n",
    "    for i, word in enumerate(indexlist):\n",
    "        if word[0] in vocab:\n",
    "            vocab.get(word[0]).append(word[1])       \n",
    "        else:\n",
    "            vocab[word[0]] = [word[1]]\n",
    "            \n",
    "    # stop_word processing if the 2nd parameter was given 'True'    \n",
    "    if stop_words_processing == True:\n",
    "        stopwords = stop_words(vocab, 10)\n",
    "        for k, v in list(vocab.items()):\n",
    "            if k in stopwords:\n",
    "                del vocab[k]    \n",
    "   \n",
    "\n",
    "    if query:\n",
    "        for k, v in list(vocab.items()):\n",
    "            if k == query:\n",
    "                print(f\"The doc ID for your query '{k}' is   {v}\")\n",
    "                return\n",
    "    \n",
    "    # sum of the length of the postings lists \n",
    "    sum_len_values = sum(len(dct) for dct in vocab.values())           \n",
    "    return len(vocab), sum_len_values # len(vocab) for the size of the dictionary     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "headed-array",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3684, 50966)\n",
      "(3674, 43163)\n",
      "The doc ID for your query 'school' is   ['72', '111', '223', '224', '268', '385', '431', '494', '532', '553', '554', '564', '581', '582', '996']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# before stop words processing \n",
    "print(inverted_index(words_after, False))\n",
    "\n",
    "# after stop words processing \n",
    "print(inverted_index(words_after, True))\n",
    "\n",
    "# simple query \n",
    "print(inverted_index(words_after, True, 'school'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "centered-assault",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "    \n",
    "for i, word in enumerate(words_after):\n",
    "    if word[0] in vocab:\n",
    "        vocab.get(word[0]).append(word[1])       \n",
    "    else:\n",
    "        vocab[word[0]] = [word[1]]\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "wrong-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function that performs the intersection \n",
    "between two or more posting lists \n",
    "'''\n",
    "\n",
    "def intersect(lst1, lst2):\n",
    "    # e.g. str '2' -> int 2 \n",
    "    lst1 = list(map(int, lst1))\n",
    "    lst2 = list(map(int, lst2))\n",
    "    \n",
    "    res = [];\n",
    "    i=0 ; j = 0; compare_count = 0;\n",
    "    \n",
    "    while i<len(lst1) and j<len(lst2):\n",
    "        if lst1[i] == lst2[j]:\n",
    "            res.append(lst1[i])\n",
    "            i += 1\n",
    "            j += 1\n",
    "            compare_count += 1\n",
    "        \n",
    "        elif lst1[i] < lst2[j]:\n",
    "            i += 1\n",
    "            compare_count += 1 \n",
    "        \n",
    "        elif lst1[i]:\n",
    "            j += 1\n",
    "            compare_count += 1 \n",
    "\n",
    "            \n",
    "    print(\"No.of comparison: \", compare_count)\n",
    "            \n",
    "    return res\n",
    "\n",
    "\n",
    "def intersect_w_skip(lst1, lst2):\n",
    "    lst1 = list(map(int, lst1))\n",
    "    lst2 = list(map(int, lst2))\n",
    "    \n",
    "    res = [];\n",
    "    i=0 ; j = 0; compare_count = 0;\n",
    "    \n",
    "    while i<len(lst1) and j<len(lst2):\n",
    "        if lst1[i] == lst2[j]:\n",
    "            res.append(lst1[i])\n",
    "            i += 1\n",
    "            j += 1\n",
    "            compare_count += 1\n",
    "        \n",
    "        elif lst1[i] < lst2[j]:\n",
    "            i += 1\n",
    "            compare_count += 1 \n",
    "        \n",
    "        elif lst1[i]:\n",
    "            j += 1\n",
    "            compare_count += 1 \n",
    "\n",
    "            \n",
    "    print(\"No.of comparison: \", compare_count)\n",
    "            \n",
    "    return res\n",
    "\n",
    "def query(indexlist):\n",
    "    vocab = {}\n",
    "    for i, word in enumerate(indexlist):\n",
    "        if word[0] in vocab:\n",
    "            vocab.get(word[0]).append(word[1])       \n",
    "        else:\n",
    "            vocab[word[0]] = [word[1]]\n",
    "            \n",
    "    stopwords = stop_words(vocab, 10)\n",
    "    \n",
    "    for k, v in list(vocab.items()):\n",
    "        if k in stopwords:\n",
    "            del vocab[k]    \n",
    "    \n",
    "    lst = []; \n",
    "    \n",
    "    user_input = input(\"Enter an intersection query (format: a AND b): \")\n",
    "    input_list = user_input.split(' AND ')\n",
    "    \n",
    "    for i, query in enumerate(input_list):\n",
    "        for k, v in list(vocab.items()):\n",
    "            if k == query:\n",
    "                lst.append(v)\n",
    "                \n",
    "    sorted_list = sorted(lst, key=len)\n",
    "    res = intersect(sorted_list[0], sorted_list[-1])\n",
    "    \n",
    "    if len(lst) == 2:\n",
    "        return res \n",
    "\n",
    "    else:\n",
    "        k = 1\n",
    "        while k < len(sorted_list)-1:\n",
    "            res = intersect(res, sorted_list[k])\n",
    "            k += 1\n",
    "            \n",
    "        return res\n",
    "            \n",
    "        \n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "cleared-coral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter an intersection query (format: a AND b):  school AND kids AND really\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.of comparison:  130\n",
      "No.of comparison:  11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[72, 224, 385]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# school AND kids AND really\n",
    "query(words_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "tough-knitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranked queries for the query 'school AND kids AND really' \n",
    "\n",
    "with open('index_rank.txt') as f:\n",
    "    # after lower casing \n",
    "    words_after_rank = [line.split() for line in f.read().split('\\n') if line]\n",
    "    \n",
    "    \n",
    "for i in range(len(words_after)):\n",
    "    words_after_rank[i][0] = int(words_after_rank[i][0])\n",
    "    words_after_rank[i][2] = int(words_after_rank[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "earned-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "dramatic-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_total_doc = 3 \n",
    "doc_id = ['72', '224', '385']\n",
    "\n",
    "\n",
    "vocab = []\n",
    "\n",
    "for i in words_after_rank:\n",
    "    if i[2] == 72:\n",
    "        vocab.append(i[1])\n",
    "        \n",
    "    elif i[2] == 224:\n",
    "        vocab.append(i[1])\n",
    "        \n",
    "    elif i[2] == 385:\n",
    "        vocab.append(i[1])\n",
    "        \n",
    "vocab = sorted(list(set(vocab)))\n",
    "\n",
    "df1 = pd.DataFrame({'doc_id': doc_id})\n",
    "df = pd.DataFrame(vocab).T\n",
    "df = df.rename(columns=df.iloc[0])\n",
    "df = df.drop(df.index[0])\n",
    "df = pd.concat([df1, df])\n",
    "\n",
    " \n",
    "\n",
    "for i in words_after_rank:\n",
    "    if i[2] == 72:\n",
    "        pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "asian-listing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'</th>\n",
       "      <th>,</th>\n",
       "      <th>-</th>\n",
       "      <th>.</th>\n",
       "      <th>...</th>\n",
       "      <th>?</th>\n",
       "      <th>a</th>\n",
       "      <th>always</th>\n",
       "      <th>anyone</th>\n",
       "      <th>bad</th>\n",
       "      <th>...</th>\n",
       "      <th>was</th>\n",
       "      <th>we</th>\n",
       "      <th>well</th>\n",
       "      <th>what'</th>\n",
       "      <th>you</th>\n",
       "      <th>you'</th>\n",
       "      <th>–</th>\n",
       "      <th>“</th>\n",
       "      <th>”</th>\n",
       "      <th>…</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     '    ,    -    .  ...    ?    a always anyone  bad  ...  was   we well  \\\n",
       "0  NaN  NaN  NaN  NaN  NaN  NaN  NaN    NaN    NaN  NaN  ...  NaN  NaN  NaN   \n",
       "1  NaN  NaN  NaN  NaN  NaN  NaN  NaN    NaN    NaN  NaN  ...  NaN  NaN  NaN   \n",
       "2  NaN  NaN  NaN  NaN  NaN  NaN  NaN    NaN    NaN  NaN  ...  NaN  NaN  NaN   \n",
       "\n",
       "  what'  you you'    –    “    ”    …  \n",
       "0   NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1   NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2   NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[3 rows x 74 columns]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "increasing-stupid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. skip pointer \n",
    "# 2. tf-idf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-split",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
